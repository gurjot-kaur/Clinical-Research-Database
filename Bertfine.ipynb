{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bertfine.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOVkmd0bo61BHD6aLY8benl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurjot-kaur/Clinical-Research-Database/blob/master/Bertfine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8prXFBHskqs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "099cfd92-cb22-4a56-c368-68d1aace9a4a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll4x7dUBk1Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f5ca01d7-2c73-400b-9911-af06bdf0288b"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhBddZs8k4nD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "602546b1-6459-4893-993b-bf6adfb6d9bd"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7PJi7Rik83e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "c6d6ac9c-8af8-4875-a06b-29bdd074aff2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"train.tsv\", delimiter='\\t', header=None, names=['label','tweet'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,041,119\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>351557</th>\n",
              "      <td>1</td>\n",
              "      <td>ruhut please deh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855030</th>\n",
              "      <td>2</td>\n",
              "      <td>back home tired tan and smiling ha ha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837978</th>\n",
              "      <td>2</td>\n",
              "      <td>gave us enough time to have a few beers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42130</th>\n",
              "      <td>1</td>\n",
              "      <td>one day old baby dies of coronavirus complicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185117</th>\n",
              "      <td>0</td>\n",
              "      <td>boo should have told me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387656</th>\n",
              "      <td>1</td>\n",
              "      <td>the start of a new day at work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652536</th>\n",
              "      <td>1</td>\n",
              "      <td>i got sin i jus got bought pairs of shoes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459344</th>\n",
              "      <td>2</td>\n",
              "      <td>but i do still like her and want to see her in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441701</th>\n",
              "      <td>0</td>\n",
              "      <td>haven t wanted to commit so still haven t boug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819913</th>\n",
              "      <td>2</td>\n",
              "      <td>not to worry you won t be out the back on your...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label                                              tweet\n",
              "351557      1                                   ruhut please deh\n",
              "855030      2              back home tired tan and smiling ha ha\n",
              "837978      2            gave us enough time to have a few beers\n",
              "42130       1  one day old baby dies of coronavirus complicat...\n",
              "185117      0                            boo should have told me\n",
              "387656      1                     the start of a new day at work\n",
              "652536      1          i got sin i jus got bought pairs of shoes\n",
              "459344      2  but i do still like her and want to see her in...\n",
              "441701      0  haven t wanted to commit so still haven t boug...\n",
              "819913      2  not to worry you won t be out the back on your..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0coW7LWBltzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = df.tweet.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lftu_Flql63F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1663e614-9209-4abd-f523-5cc00001697c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWByRkI6mDwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e26b3a12-8165-4214-c039-064c7476b672"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', tweets[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  road to recovery central arkansas veterans healthcare system discharged its first covid long term ventilator pa\n",
            "Tokenized:  ['road', 'to', 'recovery', 'central', 'arkansas', 'veterans', 'healthcare', 'system', 'discharged', 'its', 'first', 'co', '##vid', 'long', 'term', 'vent', '##ila', '##tor', 'pa']\n",
            "Token IDs:  [2346, 2000, 7233, 2430, 6751, 8244, 9871, 2291, 14374, 2049, 2034, 2522, 17258, 2146, 2744, 18834, 11733, 4263, 6643]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ5JKCEQmPlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13a4c4cc-3638-4233-fadc-708c270a839b"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for tweet in tweets:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(tweet, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYUs96Pzmbn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3893d4ff-5c7f-4b88-d807-7cad14def504"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for tweet in tweets:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  road to recovery central arkansas veterans healthcare system discharged its first covid long term ventilator pa\n",
            "Token IDs: tensor([  101,  2346,  2000,  7233,  2430,  6751,  8244,  9871,  2291, 14374,\n",
            "         2049,  2034,  2522, 17258,  2146,  2744, 18834, 11733,  4263,  6643,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnV4yqJGnUh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9b6e58da-3bc0-4b1b-b18a-781d4abada6d"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "937,007 training samples\n",
            "104,112 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8euK6cnxnd3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW8hq18qpWOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28e16378-a3e7-43a0-de3e-a29bdc913a04"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8LASx7pbnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "19f640a1-9bd6-49f3-88a9-c054a9e06c18"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjXoxRYCpi0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT0ivC03ptRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeEDTWcMpvop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1NTvPuQpyut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCVPXekHp1No",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "045783d9-a359-4ff0-8274-5cbba461842a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 5000 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch 5,000  of  29,282.    Elapsed: 0:32:09.\n",
            "  Batch 10,000  of  29,282.    Elapsed: 1:04:17.\n",
            "  Batch 15,000  of  29,282.    Elapsed: 1:36:25.\n",
            "  Batch 20,000  of  29,282.    Elapsed: 2:08:33.\n",
            "  Batch 25,000  of  29,282.    Elapsed: 2:40:40.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 3:08:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:06:23\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch 5,000  of  29,282.    Elapsed: 0:32:09.\n",
            "  Batch 10,000  of  29,282.    Elapsed: 1:04:15.\n",
            "  Batch 15,000  of  29,282.    Elapsed: 1:36:22.\n",
            "  Batch 20,000  of  29,282.    Elapsed: 2:08:30.\n",
            "  Batch 25,000  of  29,282.    Elapsed: 2:40:38.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 3:08:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:06:23\n",
            "\n",
            "Training complete!\n",
            "Total training took 6:29:05 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYfzhdnvzDCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "66264fd5-0955-4bb4-e158-a4f8c0748222"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3:08:10</td>\n",
              "      <td>0:06:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.87</td>\n",
              "      <td>3:08:08</td>\n",
              "      <td>0:06:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.18         0.44           0.86       3:08:10         0:06:23\n",
              "2               0.14         0.44           0.87       3:08:08         0:06:23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x5jOQ9KaziV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "0ce32bc7-4e17-4329-dfde-08a2cf4c38e3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejPKICzuMLOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a9365c34-1dd6-49a7-f2c8-d81426881339"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IGMn_PPMUnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "65c02b25-eb02-4f75-a270-2446aa989ae7"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427964K\n",
            "-rw-r--r-- 1 root root      2K Apr 17 03:31 config.json\n",
            "-rw-r--r-- 1 root root 427722K Apr 17 03:31 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Apr 17 03:31 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Apr 17 03:31 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Apr 17 03:31 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnLunWzMaj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05e1b20c-2d64-498c-f281-72cd4cd7e5ae"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Apr 17 03:31 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgRqYEZ_MheB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "57e219b2-f356-437d-8e90-8de28937258b"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jmH9oeuMj9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b50a4e71-3cdf-4db4-fae2-64d48e9cab98"
      },
      "source": [
        "!cp -r ./model_save/ \"./drive/Model/\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot create directory './drive/Model/': Operation not supported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3PkGjXdO05c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3e8b6526-f5ea-4f17-fbc7-e8cfc6fb0801"
      },
      "source": [
        "test_df = pd.read_csv('testtweets.csv', header=None)\n",
        "test_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a federal judge rejected a request from r kell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wearing plastic gloves throw them out after yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hotels around the world are illuminating vacan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aerial footage above south florida shows hundr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0                                              Tweet\n",
              "1  a federal judge rejected a request from r kell...\n",
              "2  wearing plastic gloves throw them out after yo...\n",
              "3  hotels around the world are illuminating vacan...\n",
              "4  aerial footage above south florida shows hundr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePyPyx6uO_sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0ipi_vHM0du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}